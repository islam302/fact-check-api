"""
Locust Load Testing File
Run with: locust -f load_test_locust.py --host=http://localhost:8000

This provides a web UI for load testing with real-time statistics
Access the UI at: http://localhost:8089
"""
from locust import HttpUser, task, between
import random

# Test queries
TEST_QUERIES = [
    "Ø£Ø¹Ù„Ù†Øª ÙˆÙƒØ§Ù„Ø© Ø§Ù„ÙØ¶Ø§Ø¡ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ© Ù†Ø§Ø³Ø§ Ø¹Ù† Ø§ÙƒØªØ´Ø§Ù ÙƒÙˆÙƒØ¨ Ø¬Ø¯ÙŠØ¯",
    "Ø§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ ÙŠØ²ÙˆØ± Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©",
    "Ø§Ø±ØªÙØ§Ø¹ Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù†ÙØ· Ø¥Ù„Ù‰ Ù…Ø³ØªÙˆÙŠØ§Øª Ù‚ÙŠØ§Ø³ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©",
    "Ù…Ù†Ø¸Ù…Ø© Ø§Ù„ØµØ­Ø© Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ© ØªØ­Ø°Ø± Ù…Ù† ÙÙŠØ±ÙˆØ³ Ø¬Ø¯ÙŠØ¯",
    "Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ù…Ø±ÙƒØ²ÙŠ ÙŠØ±ÙØ¹ Ø£Ø³Ø¹Ø§Ø± Ø§Ù„ÙØ§Ø¦Ø¯Ø©",
    "Ø´Ø±ÙƒØ© ØªØ³Ù„Ø§ ØªØ·Ù„Ù‚ Ø³ÙŠØ§Ø±Ø© ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©",
    "Ø§Ù„Ø£Ù…Ù… Ø§Ù„Ù…ØªØ­Ø¯Ø© ØªØ¹Ù‚Ø¯ Ù‚Ù…Ø© Ø·Ø§Ø±Ø¦Ø© Ù„Ù„Ù…Ù†Ø§Ø®",
    "Ø§ÙƒØªØ´Ø§Ù Ø¹Ù„Ø§Ø¬ Ø¬Ø¯ÙŠØ¯ Ù„Ù…Ø±Ø¶ Ø§Ù„Ø³ÙƒØ±ÙŠ",
    "Ø§ÙØªØªØ§Ø­ Ø£ÙƒØ¨Ø± Ù…Ø·Ø§Ø± ÙÙŠ Ø§Ù„Ø´Ø±Ù‚ Ø§Ù„Ø£ÙˆØ³Ø·",
    "Ø¥Ø·Ù„Ø§Ù‚ Ù‚Ù…Ø± ØµÙ†Ø§Ø¹ÙŠ Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ø§ØªØµØ§Ù„Ø§Øª",
]


class FactCheckUser(HttpUser):
    """Simulates a user checking facts"""
    
    # Wait between 1-5 seconds between tasks
    wait_time = between(1, 5)
    
    @task(3)  # Weight 3: Most common - just fact check
    def check_fact_simple(self):
        """Simple fact check without content generation"""
        query = random.choice(TEST_QUERIES)
        
        self.client.post(
            "/fact_check_with_openai/",
            json={
                "query": query,
                "generate_news": False,
                "generate_tweet": False,
                "preserve_sources": False
            },
            name="Fact Check (Simple)"
        )
    
    @task(2)  # Weight 2: Common - fact check with news
    def check_fact_with_news(self):
        """Fact check with news article generation"""
        query = random.choice(TEST_QUERIES)
        
        self.client.post(
            "/fact_check_with_openai/",
            json={
                "query": query,
                "generate_news": True,
                "generate_tweet": False,
                "preserve_sources": True
            },
            name="Fact Check + News"
        )
    
    @task(1)  # Weight 1: Less common - fact check with everything
    def check_fact_full(self):
        """Full fact check with all features"""
        query = random.choice(TEST_QUERIES)
        
        self.client.post(
            "/fact_check_with_openai/",
            json={
                "query": query,
                "generate_news": True,
                "generate_tweet": True,
                "preserve_sources": True
            },
            name="Fact Check (Full)"
        )
    
    def on_start(self):
        """Called when a simulated user starts"""
        print(f"ğŸš€ New user started")
    
    def on_stop(self):
        """Called when a simulated user stops"""
        print(f"ğŸ›‘ User stopped")


"""
USAGE INSTRUCTIONS:

1. Start your Django server:
   python manage.py runserver

2. In another terminal, run Locust:
   locust -f load_test_locust.py --host=http://localhost:8000

3. Open browser and go to:
   http://localhost:8089

4. Configure the test:
   - Number of users: Start with 10
   - Spawn rate: 1-2 users per second
   - Host: http://localhost:8000

5. Click "Start swarming" to begin the test

6. Watch the real-time statistics:
   - Requests per second
   - Response times (average, min, max)
   - Failures
   - Number of users

RECOMMENDED TESTS:

Test 1: Light load (2-5 users)
- See how the system performs normally

Test 2: Medium load (10-15 users)
- Test concurrent capacity

Test 3: Heavy load (20-30 users)
- Find the breaking point

Test 4: Spike test
- Start with 5 users
- Suddenly increase to 20 users
- See how system handles sudden load

MONITORING:
- Watch response times
- Check failure rate
- Monitor server resources (CPU, RAM)
- Note when response times start increasing significantly
"""

