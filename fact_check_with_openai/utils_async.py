import os, traceback, json
import asyncio
import re
from typing import List, Dict
from dotenv import load_dotenv
from openai import AsyncOpenAI
from datetime import datetime
import aiohttp

load_dotenv()

def translate_date_references(text: str) -> str:
    """
    ÿ•ÿ±ÿ¨ÿßÿπ ÿßŸÑŸÜÿµ ŸÉŸÖÿß ŸáŸà ÿØŸàŸÜ ÿ™ÿ∫ŸäŸäÿ± ÿßŸÑŸÖÿ±ÿßÿ¨ÿπ ÿßŸÑÿ≤ŸÖŸÜŸäÿ©
    ŸÑÿ™ÿ¨ŸÜÿ® ÿ™ÿ∫ŸäŸäÿ± ŸÖÿπŸÜŸâ ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜÿØ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÉŸÑŸÖÿßÿ™ ŸÖÿ´ŸÑ "ÿßŸÑŸäŸàŸÖ"
    """
    # ÿ•ÿ±ÿ¨ÿßÿπ ÿßŸÑŸÜÿµ ŸÉŸÖÿß ŸáŸà ÿØŸàŸÜ ÿ£Ÿä ÿ™ÿπÿØŸäŸÑ
    return text

async def generate_professional_news_article_from_analysis_async(claim_text: str, case: str, talk: str, sources: List[Dict], lang: str = "ar", client: AsyncOpenAI = None) -> str:
    """
    Generate a professional news article based on fact-check analysis and sources
    Uses the analysis (talk) and sources to create a balanced, journalistic piece
    """
    
    # Prepare sources context
    if not sources:
        sources_context = "No specific sources available for this investigation."
    else:
        sources_context = "\n\n".join([
            f"**Source {i+1}:**\n"
            f"Title: {source.get('title', 'N/A')}\n"
            f"URL: {source.get('url', 'N/A')}\n"
            f"Snippet: {source.get('snippet', 'N/A')}"
            for i, source in enumerate(sources[:5])  # Limit to 5 sources
        ])
    
    # Determine the prompt based on the case
    if case.lower() in {"ÿ≠ŸÇŸäŸÇŸä", "true", "vrai", "verdadero", "pravda"}:
        # TRUE case - Use the specific prompt for confirmed news
        FACT_CHECK_NEWS_PROMPT = f"""
You are a senior international news agency journalist writing in {lang.upper()} language.

Write a professional news article in the style of international news agencies based on the provided headline and analysis.

**CRITICAL INSTRUCTIONS FOR TRUE NEWS:**
- Start DIRECTLY with the news event/statement itself (e.g., "ÿßÿÆÿ™Ÿèÿ™ŸÖÿ™ ÿßŸÑŸäŸàŸÖ ÿ£ÿπŸÖÿßŸÑ..." or "Today concluded the works of...")
- Write as a DIRECT NEWS REPORT, NOT as analysis or verification
- First paragraph: Report the main event naturally with details (who, what, when, where, participants, etc.)
- Second paragraph: Discuss the topics, themes, or issues that were addressed/covered
- Third paragraph: Provide additional context about sessions, discussions, or highlights
- AVOID any mention of "verification", "fact-check", "results", "ÿ™ÿ≠ŸÇŸÇ", "ŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿ™ÿ≠ŸÇŸÇ" anywhere in the article
- Write naturally and smoothly as if reporting events as they happened
- Mention official sources and statements naturally

**STRUCTURE TEMPLATE FOR TRUE NEWS:**
1. **Opening Paragraph**: Start directly with the event (e.g., "ÿßÿÆÿ™Ÿèÿ™ŸÖÿ™ ÿßŸÑŸäŸàŸÖ ÿ£ÿπŸÖÿßŸÑ..." or "Today concluded...") with key details
2. **Second Paragraph**: Discuss the topics, themes, or issues that were covered
3. **Third Paragraph**: Additional context about sessions, discussions, or highlights

**REQUIREMENTS:**
- Language: {lang.upper()} entirely
- Style: Professional news reporting (like AFP, Reuters, AP)
- Tone: Neutral, factual, authoritative
- Structure: Exactly 3 paragraphs following the template above
- Length: 150-250 words
- Must follow the exact structure template
- Use professional journalistic language
- NO mention of verification or fact-checking
"""
    else:
        # UNCERTAIN case - Use the specific prompt for unconfirmed news
        FACT_CHECK_NEWS_PROMPT = f"""
You are a senior international news agency journalist writing in {lang.upper()} language.

Write a professional news article in the style of international news agencies based on the provided headline and analysis.

**CRITICAL INSTRUCTIONS FOR UNCERTAIN NEWS:**
- Start with: "ÿ™ÿØÿßŸàŸÑÿ™ ŸÖŸÜÿµÿßÿ™ ÿßŸÑÿ™ŸàÿßÿµŸÑ ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπŸä ŸÖÿ≤ÿßÿπŸÖ ÿ™ŸÅŸäÿØ ÿ®ÿ£ŸÜ [ÿßŸÑÿßÿØÿπÿßÿ°]" (or equivalent in the target language)
- Follow immediately with: "ÿ∫Ÿäÿ± ÿ£ŸÜ ŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿ™ÿ≠ŸÇŸÇ ÿ£ÿ∏Ÿáÿ±ÿ™ ÿ£ŸÜ Ÿáÿ∞ÿß ÿßŸÑÿßÿØÿπÿßÿ° ŸÑÿß ŸäŸÖŸÉŸÜ ÿ™ÿ£ŸÉŸäÿØŸá" (or equivalent: "However, verification results showed that this claim cannot be confirmed")
- Then explain the available information and why the claim cannot be confirmed
- Provide historical context or relevant background information if available
- End with a clear conclusion that the claim lacks reliable evidence

**STRUCTURE TEMPLATE:**
1. **Opening**: "ÿ™ÿØÿßŸàŸÑÿ™ ŸÖŸÜÿµÿßÿ™ ÿßŸÑÿ™ŸàÿßÿµŸÑ ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπŸä ŸÖÿ≤ÿßÿπŸÖ ÿ™ŸÅŸäÿØ ÿ®ÿ£ŸÜ [ÿßŸÑÿßÿØÿπÿßÿ°]ÿå ÿ∫Ÿäÿ± ÿ£ŸÜ ŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿ™ÿ≠ŸÇŸÇ ÿ£ÿ∏Ÿáÿ±ÿ™ ÿ£ŸÜ Ÿáÿ∞ÿß ÿßŸÑÿßÿØÿπÿßÿ° ŸÑÿß ŸäŸÖŸÉŸÜ ÿ™ÿ£ŸÉŸäÿØŸá."
2. **Body**: Explain available information, historical context, and evidence that contradicts or doesn't support the claim
3. **Conclusion**: "Ÿàÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿ∞ŸÑŸÉÿå Ÿäÿ™ÿ®ŸäŸëŸÜ ÿ£ŸÜ ÿßŸÑÿßÿØÿπÿßÿ° ÿßŸÑŸÖÿ™ÿØÿßŸàŸÑ ŸäŸÅÿ™ŸÇÿ± ÿ•ŸÑŸâ ÿ£Ÿä ÿ£ÿ≥ÿßÿ≥ ŸÖŸÜ ÿßŸÑÿ£ÿØŸÑÿ© ÿßŸÑŸÖŸàÿ´ŸàŸÇÿ©ÿå ŸàŸÑÿß ÿ™Ÿàÿ¨ÿØ ŸÖÿµÿßÿØÿ± ÿ™ÿØÿπŸÖ ÿµÿ≠ÿ™Ÿá."

**REQUIREMENTS:**
- Language: {lang.upper()} entirely
- Style: Professional news reporting
- Tone: Objective, transparent, informative
- Structure: News article format with structured paragraphs
- Length: 150-250 words
- Must follow the exact structure template above
- Use professional journalistic language
"""
    
    # Create the user message
    if case.lower() in {"ÿ≠ŸÇŸäŸÇŸä", "true", "vrai", "verdadero", "pravda"}:
        user_message = f"""
**PROVIDED DATA:**
Headline: {claim_text}
Fact-check Analysis: {talk}

**AVAILABLE SOURCES:**
{sources_context}

**EXAMPLE FORMAT FOR TRUE NEWS (ARABIC):**
ÿßÿÆÿ™Ÿèÿ™ŸÖÿ™ ÿßŸÑŸäŸàŸÖ ÿ£ÿπŸÖÿßŸÑ ÿßŸÑŸÖÿ§ÿ™ŸÖÿ± ÿßŸÑÿπÿØŸÑŸä ÿßŸÑÿØŸàŸÑŸä ŸÅŸä ÿßŸÑÿπÿßÿµŸÖÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäÿ© ÿßŸÑÿ±Ÿäÿßÿ∂ÿå ÿ™ÿ≠ÿ™ ÿ¥ÿπÿßÿ± "ŸÜŸèŸäŸéÿ≥ŸêŸëÿ± ÿßŸÑŸàÿµŸàŸÑ ŸÑŸÑÿπÿØÿßŸÑÿ© ÿ®ÿ™ŸÇŸÜŸäÿßÿ™ ÿ±ŸÇŸÖŸäÿ©"ÿå Ÿàÿ¥ÿßÿ±ŸÉ ŸÅŸäŸá ÿ£ŸÉÿ´ÿ± ŸÖŸÜ 4000 ŸÖÿ¥ÿßÿ±ŸÉÿå Ÿà 50 ŸÖÿ™ÿ≠ÿØÿ´ÿßŸã ŸàÿÆÿ®Ÿäÿ±ÿßŸã ÿØŸàŸÑŸäŸëÿßŸã.

ŸàŸÜÿßŸÇÿ¥ ÿßŸÑŸÖÿ§ÿ™ŸÖÿ± ŸÇÿ∂ÿßŸäÿß ÿπÿØÿ© ÿ£ÿ®ÿ±ÿ≤Ÿáÿß ŸÖÿ≥ÿ™ŸÇÿ®ŸÑ ÿßŸÑŸÇÿ∂ÿßÿ° ŸÅŸä ÿ∏ŸÑ ÿßŸÑÿ™ÿ≠ŸàŸÑ ÿßŸÑÿ±ŸÇŸÖŸäÿå ŸàÿßŸÑÿ™ÿ¨ÿßÿ±ÿ® ÿßŸÑÿØŸàŸÑŸäÿ© ŸÅŸä ÿßŸÑÿ™ÿ≠ŸàŸÑ ÿßŸÑÿ±ŸÇŸÖŸäÿå ŸàÿßŸÑÿ®ÿπÿØ ÿßŸÑŸÇÿßŸÜŸàŸÜŸä ŸÑŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸäÿå Ÿàÿ™Ÿàÿ∏ŸäŸÅ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸÅŸä ÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑÿπÿØÿßŸÑÿ©ÿå Ÿàÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ŸÑÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑÿπÿØÿßŸÑÿ©ÿå ŸàŸÖÿ≥ÿ™ŸÇÿ®ŸÑ ÿßŸÑŸàÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿ®ÿØŸäŸÑÿ© ŸÑÿ™ÿ≥ŸàŸäÿ© ÿßŸÑŸÜÿ≤ÿßÿπÿßÿ™ ŸÅŸä ÿ∏ŸÑ ÿßŸÑÿ™ÿ≠ŸàŸÑ ÿßŸÑÿ±ŸÇŸÖŸä.

Ÿàÿ≥ŸÑŸéŸëÿ∑ÿ™ ÿßŸÑÿ¨ŸÑÿ≥ÿßÿ™ ÿßŸÑÿ≠Ÿàÿßÿ±Ÿäÿ© ÿßŸÑÿ∂Ÿàÿ° ÿπŸÑŸâ ŸÖÿ¨ŸÖŸàÿπÿ© ŸÖŸÜ ÿßŸÑŸÖŸàÿ∂Ÿàÿπÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ÿ™ŸÜÿßŸàŸÑ ÿØŸàÿ± ÿßŸÑÿ™ÿ≠ŸàŸÑ ÿßŸÑÿ±ŸÇŸÖŸä ŸàÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸÅŸä ÿßŸÑŸÖÿ¨ÿßŸÑŸäŸÜ ÿßŸÑÿπÿØŸÑŸä ŸàÿßŸÑŸÇÿ∂ÿßÿ¶Ÿä.

**INSTRUCTIONS:**
- Follow the exact structure shown in the example above
- First paragraph: Start directly with the event (who, what, when, where, participants)
- Second paragraph: Discuss the topics, themes, or issues that were covered
- Third paragraph: Additional context about sessions, discussions, or highlights
- Write as a direct news report, NOT as verification or fact-check
- AVOID any mention of "verification", "fact-check", "results", "ÿ™ÿ≠ŸÇŸÇ", "ŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿ™ÿ≠ŸÇŸÇ"
- Use the analysis data to inform your reporting, but present it as breaking news
- Adapt the structure to the target language ({lang.upper()}) while maintaining the same meaning
"""
    else:
        user_message = f"""
**PROVIDED DATA:**
Headline: {claim_text}
Fact-check Analysis: {talk}

**AVAILABLE SOURCES:**
{sources_context}

**EXAMPLE FORMAT FOR UNCERTAIN NEWS (ARABIC):**
ÿ™ÿØÿßŸàŸÑÿ™ ŸÖŸÜÿµÿßÿ™ ÿßŸÑÿ™ŸàÿßÿµŸÑ ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπŸä ŸÖÿ≤ÿßÿπŸÖ ÿ™ŸÅŸäÿØ ÿ®ÿ£ŸÜ [ÿßŸÑÿßÿØÿπÿßÿ°]ÿå ÿ∫Ÿäÿ± ÿ£ŸÜ ŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿ™ÿ≠ŸÇŸÇ ÿ£ÿ∏Ÿáÿ±ÿ™ ÿ£ŸÜ Ÿáÿ∞ÿß ÿßŸÑÿßÿØÿπÿßÿ° ŸÑÿß ŸäŸÖŸÉŸÜ ÿ™ÿ£ŸÉŸäÿØŸá.

Ÿàÿ®ÿ≠ÿ≥ÿ® ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÖÿ™ÿßÿ≠ÿ©ÿå [ÿ¥ÿ±ÿ≠ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÖÿ™ÿßÿ≠ÿ© ŸàÿßŸÑÿ≥ÿ®ÿ® ŸÅŸä ÿπÿØŸÖ ÿßŸÑÿ™ÿ£ŸÉŸäÿØ]. [ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿ™ÿßÿ±ŸäÿÆŸäÿ© ÿ£Ÿà ÿ≥ŸäÿßŸÇ ÿ•ÿ∞ÿß ŸÉÿßŸÜ ŸÖÿ™ÿßÿ≠ÿßŸã].

Ÿàÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿ∞ŸÑŸÉÿå Ÿäÿ™ÿ®ŸäŸëŸÜ ÿ£ŸÜ ÿßŸÑÿßÿØÿπÿßÿ° ÿßŸÑŸÖÿ™ÿØÿßŸàŸÑ ŸäŸÅÿ™ŸÇÿ± ÿ•ŸÑŸâ ÿ£Ÿä ÿ£ÿ≥ÿßÿ≥ ŸÖŸÜ ÿßŸÑÿ£ÿØŸÑÿ© ÿßŸÑŸÖŸàÿ´ŸàŸÇÿ©ÿå ŸàŸÑÿß ÿ™Ÿàÿ¨ÿØ ŸÖÿµÿßÿØÿ± ÿ™ÿØÿπŸÖ ÿµÿ≠ÿ™Ÿá.

**INSTRUCTIONS:**
- Follow the exact structure shown in the example above
- Use the analysis data to explain why the claim cannot be confirmed
- Include historical context or relevant background when available
- End with the conclusion that the claim lacks reliable evidence
- Adapt the structure to the target language ({lang.upper()}) while maintaining the same meaning
"""
    
    try:
        print("üì∞ Generating news article...")
        
        response = await client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": FACT_CHECK_NEWS_PROMPT}
            ],
            temperature=0.1,  # Very low temperature for factual, measured content
            max_tokens=400,   # Allow enough tokens for 150-250 words
            top_p=0.9,        # Focus on most likely responses
            frequency_penalty=0.1,  # Slight penalty to avoid repetition
            presence_penalty=0.1    # Encourage diverse vocabulary
        )
        
        article = response.choices[0].message.content.strip()
        print("‚úÖ News article generated successfully")
        return article
        
    except Exception as e:
        print(f"‚ùå Error generating news article: {e}")
        error_messages = {
            "ar": "ÿπÿ∞ÿ±ÿßŸãÿå ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ ÿ£ÿ´ŸÜÿßÿ° ŸÉÿ™ÿßÿ®ÿ© ÿßŸÑŸÖŸÇÿßŸÑ ÿßŸÑÿ•ÿÆÿ®ÿßÿ±Ÿä. Ÿäÿ±ÿ¨Ÿâ ÿßŸÑŸÖÿ≠ÿßŸàŸÑÿ© ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ.",
            "en": "Sorry, an error occurred while writing the news article. Please try again.",
            "fr": "D√©sol√©, une erreur s'est produite lors de la r√©daction de l'article de presse. Veuillez r√©essayer.",
            "es": "Lo siento, ocurri√≥ un error al escribir el art√≠culo de noticias. Por favor, int√©ntalo de nuevo.",
        }
        return error_messages.get(lang, error_messages["en"])

async def generate_x_tweet_async(claim_text: str, case: str, talk: str, sources: List[Dict], lang: str = "ar", client: AsyncOpenAI = None) -> str:
    """
    Generate a professional X (Twitter) tweet based on fact-check results
    Optimized for X platform with proper formatting and engagement
    """
    
    # X/Twitter specific prompt
    X_TWEET_PROMPT = f"""
You are a professional social media journalist and X (Twitter) content creator with expertise in:

**X PLATFORM EXPERTISE:**
1. **Social Media Journalist**: Create engaging, accurate news content for X
2. **Viral Content Creator**: Understand what drives engagement on X
3. **Fact-Checking Specialist**: Present verified information clearly
4. **Crisis Communication**: Handle sensitive information responsibly
5. **Community Manager**: Engage audiences while maintaining credibility
6. **Digital Storyteller**: Tell compelling stories in limited characters
7. **Breaking News Reporter**: Handle urgent, time-sensitive information
8. **Public Interest Communicator**: Serve public interest on social media

**X PLATFORM REQUIREMENTS:**
- Maximum 280 characters (strict limit)
- Use hashtags strategically (2-3 relevant hashtags)
- Include emojis appropriately for engagement
- Write for mobile-first audience
- Use clear, concise language
- Include call-to-action when appropriate
- Maintain professional credibility
- Respect X community guidelines

**TWEET STRUCTURE FOR FACT-CHECKING:**
1. **Hook**: Attention-grabbing opening
2. **Fact**: Clear statement of the fact-check result
3. **Context**: Brief explanation or key detail
4. **Hashtags**: Relevant, trending hashtags
5. **Emojis**: Strategic use for engagement and clarity

**LANGUAGE POLICY:**
- Write ENTIRELY in {lang.upper()} language
- Use professional but engaging tone
- Adapt to social media communication style
- Maintain journalistic credibility
- Use appropriate emojis for the language/culture

**ENGAGEMENT STRATEGY:**
- Start with compelling hook
- Use numbers/statistics when available
- Include relevant hashtags
- Use emojis strategically
- End with clear conclusion or call-to-action
- Maintain professional credibility

**RESPONSE FORMAT:**
Generate a single, professional X tweet (max 280 characters) that:
- Clearly states the fact-check result
- Engages the audience appropriately
- Maintains journalistic credibility
- Uses relevant hashtags and emojis
- Respects X platform guidelines
"""

    # Prepare context based on fact-check result (only True or Uncertain)
    if case.lower() in {"ÿ≠ŸÇŸäŸÇŸä", "true", "vrai", "verdadero", "pravda"}:
        result_emoji = "‚úÖ"
        result_text = "ÿ≠ŸÇŸäŸÇŸä" if lang == "ar" else "TRUE"
        tone = "confirming"
    else:  # uncertain
        result_emoji = "‚ö†Ô∏è"
        result_text = "ÿ∫Ÿäÿ± ŸÖÿ§ŸÉÿØ" if lang == "ar" else "UNCERTAIN"
        tone = "uncertain"

    # Create the user message
    user_message = f"""
**FACT-CHECK RESULT:**
Claim: {claim_text}
Result: {case} ({result_text})
Analysis: {talk}

**SOURCES:**
{len(sources)} sources available

**INSTRUCTIONS:**
Create a professional X tweet that:
1. Clearly communicates the fact-check result
2. Engages the audience appropriately
3. Uses relevant hashtags and emojis
4. Maintains journalistic credibility
5. Respects X platform guidelines
6. Stays within 280 character limit

**TONE:** {tone}
**LANGUAGE:** {lang.upper()}
**PLATFORM:** X (Twitter)
**CHARACTER LIMIT:** 280 characters maximum
"""

    try:
        print("üê¶ Generating X tweet...")
        
        response = await client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": X_TWEET_PROMPT},
                {"role": "user", "content": user_message}
            ],
            temperature=0.3,  # Balanced creativity and accuracy
            max_tokens=100,   # Optimized for tweet length (280 chars max)
            top_p=0.9,
            frequency_penalty=0.1,
            presence_penalty=0.1
        )
        
        tweet = response.choices[0].message.content.strip()
        
        # Ensure tweet is within character limit
        if len(tweet) > 280:
            tweet = tweet[:277] + "..."
        
        print("‚úÖ X tweet generated successfully")
        return tweet
        
    except Exception as e:
        print(f"‚ùå Error generating X tweet: {e}")
        error_messages = {
            "ar": "‚ö†Ô∏è ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ ÿ£ÿ´ŸÜÿßÿ° ÿ•ŸÜÿ¥ÿßÿ° ÿßŸÑÿ™ÿ∫ÿ±ŸäÿØÿ©. Ÿäÿ±ÿ¨Ÿâ ÿßŸÑŸÖÿ≠ÿßŸàŸÑÿ© ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ.",
            "en": "‚ö†Ô∏è An error occurred while generating the tweet. Please try again.",
            "fr": "‚ö†Ô∏è Une erreur s'est produite lors de la g√©n√©ration du tweet. Veuillez r√©essayer.",
            "es": "‚ö†Ô∏è Ocurri√≥ un error al generar el tweet. Por favor, int√©ntalo de nuevo.",
        }
        return error_messages.get(lang, error_messages["en"])

SERPAPI_KEY = os.getenv("SERPAPI_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o")
SERPAPI_HL = os.getenv("SERPAPI_HL", "ar")
SERPAPI_GL = os.getenv("SERPAPI_GL", "")
NEWS_AGENCIES = [d.strip() for d in os.getenv("NEWS_AGENCIES", "aljazeera.net,una-oic.org,bbc.com").split(",") if d.strip()]

if not SERPAPI_KEY or not OPENAI_API_KEY:
    raise RuntimeError("‚ö†Ô∏è ÿ±ÿ¨ÿßÿ°Ÿã ÿ∂ÿπ SERPAPI_KEY Ÿà OPENAI_API_KEY ŸÅŸä .env")

# Create async OpenAI client
async_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

async def _lang_hint_from_claim_async(text: str) -> str:
    try:
        resp = await async_client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": "Detect the input language and return ONLY its ISO 639-1 code (like ar, en, fr, es, de)."},
                {"role": "user", "content": text.strip()},
            ],
            temperature=0.0,
            max_tokens=5
        )
        lang = (resp.choices[0].message.content or "").strip().lower()
        if len(lang) == 2:
            return lang
    except Exception:
        pass

    # fallback
    ar_count = sum(1 for ch in text if '\u0600' <= ch <= '\u06FF')
    ratio = ar_count / max(1, len(text))
    return "ar" if ratio >= 0.15 else "en"

async def _fetch_serp_async(session: aiohttp.ClientSession, query: str, extra: Dict | None = None, num: int = 10) -> List[Dict]:
    url = "https://serpapi.com/search.json"
    params = {
        "q": query,
        "api_key": SERPAPI_KEY,
        "hl": SERPAPI_HL,
        "gl": SERPAPI_GL,
        "num": num
    }
    if extra:
        params.update(extra)
    try:
        print(f"üîç Fetching: {query}")
        async with session.get(url, params=params, timeout=aiohttp.ClientTimeout(total=20)) as response:
            response.raise_for_status()
            data = await response.json()
            results = []
            for it in data.get("organic_results", []):
                results.append({
                    "title": it.get("title") or "",
                    "snippet": it.get("snippet") or (it.get("snippet_highlighted_words", [""]) or [""])[0],
                    "link": it.get("link") or it.get("displayed_link") or "",
                })
            print(f"‚úÖ Found {len(results)} results for query: {query}")
            return [r for r in results if r["title"] or r["snippet"] or r["link"]]
    except Exception as e:
        print(f"‚ùå Error fetching from SerpAPI: {e}")
        return []

FACT_PROMPT_SYSTEM = (
    "You are a rigorous fact-checking assistant. Use ONLY the sources provided below.\n"
    "- You can ONLY return TWO possible verdicts: True OR Uncertain.\n"
    "- If the claim is supported by credible sources with clear evidence ‚Üí verdict: True\n"
    "- If evidence is insufficient, conflicting, unclear, or off-topic ‚Üí verdict: Uncertain\n"
    "- IMPORTANT: There is NO 'False' option. If you cannot confirm something as True, mark it as Uncertain.\n"
    "- Prefer official catalogs and reputable agencies over blogs or social posts.\n"
    "- Match the claim's date/place/magnitude when relevant; do not infer beyond the given sources.\n\n"

    "LANGUAGE POLICY:\n"
    "- You MUST respond **entirely** in the language specified by LANG_HINT.\n"
    "- Do NOT switch to another language or translate.\n"
    "- Examples:\n"
    "   ‚Ä¢ If LANG_HINT = 'fr' ‚Üí respond fully in French.\n"
    "   ‚Ä¢ If LANG_HINT = 'ar' ‚Üí respond fully in Arabic.\n"
    "   ‚Ä¢ If LANG_HINT = 'en' ‚Üí respond fully in English.\n"
    "   ‚Ä¢ If LANG_HINT = 'es' ‚Üí respond fully in Spanish.\n"
    "   ‚Ä¢ If LANG_HINT = 'cs' ‚Üí respond fully in Czech.\n\n"

    "FORMAT RULES:\n"
    "‚Ä¢ You MUST write all free-text fields strictly in LANG_HINT language.\n"
    "‚Ä¢ JSON keys must remain EXACTLY as: \"ÿßŸÑÿ≠ÿßŸÑÿ©\", \"talk\", \"sources\" (do not translate keys).\n"
    "‚Ä¢ The value of \"ÿßŸÑÿ≠ÿßŸÑÿ©\" must be ONLY one of these two options (localized):\n"
    "   - Arabic: ÿ≠ŸÇŸäŸÇŸä / ÿ∫Ÿäÿ± ŸÖÿ§ŸÉÿØ (ONLY these two options)\n"
    "   - English: True / Uncertain (ONLY these two options)\n"
    "   - French: Vrai / Incertain (ONLY these two options)\n"
    "   - Spanish: Verdadero / Incierto (ONLY these two options)\n"
    "   - Czech: Pravda / Nejist√© (ONLY these two options)\n"
    "‚Ä¢ NEVER use: False, Faux, Falso, Nepravda, ŸÉÿßÿ∞ÿ® - these are NOT valid options!\n"

    "RESPONSE FORMAT (JSON ONLY ‚Äî no extra text):\n"
    "{\n"
    '  \"ÿßŸÑÿ≠ÿßŸÑÿ©\": \"<Localized verdict: True OR Uncertain ONLY>\",\n'
    '  \"talk\": \"<Explanation paragraph ~350 words in LANG_HINT>\",\n'
    '  \"sources\": [ {\"title\": \"<title>\", \"url\": \"<url>\"}, ... ]\n'
    "}\n\n"

    "FINAL RULES:\n"
    "1) Output STRICTLY valid JSON (UTF-8). No extra commentary before or after.\n"
    "2) If the claim is Uncertain ‚Üí keep 'sources' as an empty array [].\n"
    "3) If the claim is True ‚Üí include ALL confirming sources (no fixed limit).\n"
    "4) Do not fabricate URLs or titles; use only provided sources.\n"
    "5) REMEMBER: You can ONLY return True or Uncertain. There is NO False option.\n"
)


def classify_source_support(source: dict, claim_text: str = "") -> str:
    """
    Classify a source as 'supporting' (ŸÖÿ§ŸäÿØ), 'opposing' (ŸÖÿπÿßÿ±ÿ∂), or 'neutral' (ŸÖÿ≠ÿßŸäÿØ)
    Based on content analysis and alignment with the claim
    """
    url = source.get("url", "").lower()
    title = source.get("title", "").lower()
    snippet = source.get("snippet", "").lower()
    claim_lower = claim_text.lower()
    
    # Supporting indicators (ŸÖÿ§ŸäÿØ)
    supporting_indicators = [
        'confirm', 'confirmed', 'verify', 'verified', 'true', 'accurate', 'correct',
        'support', 'back', 'prove', 'evidence', 'fact', 'reality', 'actual',
        'official', 'announced', 'declared', 'stated', 'reported',
        'ÿ™ÿ£ŸÉŸäÿØ', 'ÿ™ÿ£ŸÉÿØ', 'ÿµÿ≠Ÿäÿ≠', 'ÿ≠ŸÇŸäŸÇŸä', 'ÿØÿπŸÖ', 'ÿ•ÿ´ÿ®ÿßÿ™', 'ÿØŸÑŸäŸÑ', 'ŸàÿßŸÇÿπ',
        'ÿ±ÿ≥ŸÖŸä', 'ÿ£ÿπŸÑŸÜ', 'ÿµÿ±ÿ≠', 'ÿ∞ŸÉÿ±', 'ÿ£ŸÅÿßÿØ'
    ]
    
    # Opposing indicators (ŸÖÿπÿßÿ±ÿ∂)
    opposing_indicators = [
        'deny', 'denied', 'false', 'fake', 'hoax', 'misinformation', 'disinformation',
        'incorrect', 'wrong', 'untrue', 'debunk', 'refute', 'contradict', 'oppose',
        'reject', 'dispute', 'challenge', 'question', 'doubt', 'skeptical',
        'ÿ•ŸÜŸÉÿßÿ±', 'ŸÉÿßÿ∞ÿ®', 'ŸÖÿ≤ŸäŸÅ', 'ÿÆÿßÿ∑ÿ¶', 'ÿÆÿ∑ÿ£', 'ÿ±ŸÅÿ∂', 'ÿ™ŸÜÿßŸÇÿ∂', 'ŸÖÿπÿßÿ±ÿ∂ÿ©',
        'ÿ™ÿ¥ŸÉŸäŸÉ', 'ÿ¥ŸÉ', 'ÿ™ÿ≥ÿßÿ§ŸÑ', 'ÿ™ÿ≠ÿØŸä'
    ]
    
    # Neutral indicators (ŸÖÿ≠ÿßŸäÿØ)
    neutral_indicators = [
        'unclear', 'uncertain', 'unknown', 'investigating', 'pending', 'ongoing',
        'developing', 'breaking', 'update', 'report', 'news', 'analysis',
        'ÿ∫Ÿäÿ± Ÿàÿßÿ∂ÿ≠', 'ÿ∫Ÿäÿ± ŸÖÿ§ŸÉÿØ', 'ÿ∫Ÿäÿ± ŸÖÿπÿ±ŸàŸÅ', 'ÿ™ÿ≠ŸÇŸäŸÇ', 'ŸÇŸäÿØ ÿßŸÑÿ®ÿ≠ÿ´', 'ÿ¨ÿßÿ±Ÿä',
        'ÿ™ÿ∑ŸàŸäÿ±', 'ÿπÿßÿ¨ŸÑ', 'ÿ™ÿ≠ÿØŸäÿ´', 'ÿ™ŸÇÿ±Ÿäÿ±', 'ÿÆÿ®ÿ±', 'ÿ™ÿ≠ŸÑŸäŸÑ'
    ]
    
    # Count supporting indicators
    supporting_count = 0
    for indicator in supporting_indicators:
        if indicator in title or indicator in snippet:
            supporting_count += 1
    
    # Count opposing indicators
    opposing_count = 0
    for indicator in opposing_indicators:
        if indicator in title or indicator in snippet:
            opposing_count += 1
    
    # Count neutral indicators
    neutral_count = 0
    for indicator in neutral_indicators:
        if indicator in title or indicator in snippet:
            neutral_count += 1
    
    # Check for social media or blog indicators (usually less reliable)
    social_indicators = ['twitter.com', 'facebook.com', 'instagram.com', 'tiktok.com', 'blog', 'blogspot', 'wordpress.com']
    is_social_media = any(indicator in url for indicator in social_indicators)
    
    # Check for credible news sources
    credible_domains = [
        'reuters.com', 'bbc.com', 'cnn.com', 'ap.org', 'afp.com',
        'aljazeera.com', 'dw.com', 'france24.com', 'rt.com',
        'gov.', 'edu.', 'who.int', 'un.org', 'imf.org', 'worldbank.org',
        'spa.gov.sa', 'wam.ae', 'mena.gov.ae', 'qna.org.qa',
        'alwatan.com.sa', 'okaz.com.sa', 'alriyadh.com',
        'alhayat.com', 'asharqalawsat.com', 'alquds.co.uk'
    ]
    is_credible = any(domain in url for domain in credible_domains)
    
    # Weight the indicators based on credibility
    credibility_weight = 2 if is_credible else 1
    social_media_penalty = 0.5 if is_social_media else 1
    
    # Calculate weighted scores
    supporting_score = supporting_count * credibility_weight * social_media_penalty
    opposing_score = opposing_count * credibility_weight * social_media_penalty
    neutral_score = neutral_count * credibility_weight * social_media_penalty
    
    # Determine classification based on highest score
    if supporting_score > opposing_score and supporting_score > neutral_score:
        return "supporting"
    elif opposing_score > supporting_score and opposing_score > neutral_score:
        return "opposing"
    else:
        return "neutral"


def calculate_source_percentages(sources: list, claim_text: str = "") -> dict:
    """
    Calculate the percentage of supporting, opposing, and neutral sources
    """
    if not sources:
        return {
            "supporting_percentage": 0.0,
            "opposing_percentage": 0.0,
            "neutral_percentage": 0.0,
            "total_sources": 0,
            "supporting_count": 0,
            "opposing_count": 0,
            "neutral_count": 0
        }
    
    supporting_count = 0
    opposing_count = 0
    neutral_count = 0
    
    for source in sources:
        classification = classify_source_support(source, claim_text)
        if classification == "supporting":
            supporting_count += 1
        elif classification == "opposing":
            opposing_count += 1
        else:  # neutral
            neutral_count += 1
    
    total_sources = len(sources)
    supporting_percentage = (supporting_count / total_sources) * 100 if total_sources > 0 else 0
    opposing_percentage = (opposing_count / total_sources) * 100 if total_sources > 0 else 0
    neutral_percentage = (neutral_count / total_sources) * 100 if total_sources > 0 else 0
    
    return {
        "supporting_percentage": round(supporting_percentage, 1),
        "opposing_percentage": round(opposing_percentage, 1),
        "neutral_percentage": round(neutral_percentage, 1),
        "total_sources": total_sources,
        "supporting_count": supporting_count,
        "opposing_count": opposing_count,
        "neutral_count": neutral_count
    }


async def check_fact_simple_async(claim_text: str, k_sources: int = 5, generate_news: bool = False, preserve_sources: bool = False, generate_tweet: bool = False) -> dict:
    try:
        # ÿ™ÿ±ÿ¨ŸÖÿ© ÿßŸÑŸÖÿ±ÿßÿ¨ÿπ ÿßŸÑÿ≤ŸÖŸÜŸäÿ© ŸÅŸä ÿßŸÑŸÜÿµ
        processed_claim = translate_date_references(claim_text)
        print(f"üß† Fact-checking: {processed_claim}")
        
        # Create aiohttp session for parallel HTTP requests
        async with aiohttp.ClientSession() as session:
            # Run language detection and searches in parallel for maximum speed
            lang_task = _lang_hint_from_claim_async(processed_claim)
            
            # Prepare all search queries (start immediately without waiting for language)
            search_tasks = []
            
            # Add news agency searches
            for domain in NEWS_AGENCIES:
                search_tasks.append(
                    _fetch_serp_async(session, f"{processed_claim} site:{domain}", extra=None, num=2)
                )
            
            # Add general Google search
            search_tasks.append(
                _fetch_serp_async(session, processed_claim, extra=None, num=k_sources)
            )
            
            # Execute language detection and all searches in parallel
            print(f"üöÄ Running language detection + {len(search_tasks)} parallel search queries...")
            all_results = await asyncio.gather(lang_task, *search_tasks)
            
            # Extract language and search results
            lang = all_results[0]
            search_results = all_results[1:]
            
            # Combine all results
            results = []
            for result_list in search_results:
                results.extend(result_list)

        print(f"üîé Total combined results: {len(results)}")

        if not results:
            no_results_by_lang = {
                "ar": "ŸÑŸÖ Ÿäÿ™ŸÖ ÿßŸÑÿπÿ´Ÿàÿ± ÿπŸÑŸâ ŸÜÿ™ÿßÿ¶ÿ¨ ÿ®ÿ≠ÿ´.",
                "en": "No search results were found.",
                "fr": "Aucun r√©sultat de recherche trouv√©.",
                "es": "No se encontraron resultados de b√∫squeda.",
                "cs": "Nebyly nalezeny ≈æ√°dn√© v√Ωsledky vyhled√°v√°n√≠.",
                "de": "Es wurden keine Suchergebnisse gefunden.",
                "tr": "Arama sonu√ßlarƒ± bulunamadƒ±.",
                "ru": "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.",
            }
            return {"case": "ÿ∫Ÿäÿ± ŸÖÿ§ŸÉÿØ", "talk": no_results_by_lang.get(lang, no_results_by_lang["en"]), "sources": [], "news_article": None}

        def clip(s: str, n: int) -> str:
            return s.strip() if len(s) <= n else s[:n] + "‚Ä¶"

        context = "\n\n---\n\n".join(
            f"ÿπŸÜŸàÿßŸÜ: {clip(r['title'], 100)}\nŸÖŸÑÿÆÿµ: {clip(r['snippet'], 200)}\nÿ±ÿßÿ®ÿ∑: {r['link']}"
            for r in results
        )

        system_prompt = FACT_PROMPT_SYSTEM.replace("LANG_HINT", lang)
        user_msg = f"""
LANG_HINT: {lang}
CURRENT_DATE: {datetime.now().strftime('%Y-%m-%d')}

ÿßŸÑÿßÿØÿπÿßÿ°:
{processed_claim}

ÿßŸÑÿ≥ŸäÿßŸÇ:
{context}
""".strip()

        print("üì§ Sending prompt to OpenAI (fact-checking)")
        resp = await async_client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_msg},
            ],
            temperature=0.2,
            max_tokens=800,  # Enough for comprehensive fact-check
        )
        answer = (resp.choices[0].message.content or "").strip()
        
        # Clean up the answer - remove markdown code blocks if present
        if answer.startswith("```"):
            answer = answer.strip("` \n")
            if answer.lower().startswith("json"):
                answer = answer[4:].strip()
        
        # Try to extract JSON if it's wrapped in other text
        json_match = re.search(r'\{[\s\S]*\}', answer)
        if json_match:
            answer = json_match.group(0)
        
        # Parse JSON with error handling
        try:
            parsed = json.loads(answer)
        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è JSON parsing error: {e}")
            print(f"üìÑ Response content (first 500 chars): {answer[:500]}")
            
            # Try multiple strategies to fix JSON
            parsed = None  # Initialize to track if parsing succeeded
            
            # Strategy 1: Try to find the JSON object in the response
            json_match = re.search(r'\{[\s\S]*\}', answer)
            if json_match:
                answer = json_match.group(0)
                try:
                    parsed = json.loads(answer)
                except json.JSONDecodeError:
                    pass
            
            # Strategy 2: Try to fix unterminated strings
            if parsed is None and "Unterminated string" in str(e):
                # Try to fix by finding the position and closing the string
                # Simple approach: find the last incomplete string and try to close it
                lines = answer.split('\n')
                fixed_lines = []
                for i, line in enumerate(lines):
                    # Check if this line has an unterminated string (odd number of unescaped quotes)
                    unescaped_quotes = [m.start() for m in re.finditer(r'(?<!\\)"', line)]
                    if len(unescaped_quotes) % 2 != 0:
                        # Unterminated string - try to close it at the end
                        if not line.rstrip().endswith('"'):
                            # Add closing quote and remove any trailing incomplete content
                            line = line.rstrip()
                            # Try to find where the string should end
                            last_quote_pos = unescaped_quotes[-1]
                            # If there's content after the last quote, it might be incomplete
                            if len(line) > last_quote_pos + 1:
                                # Check if there's a comma or other valid JSON after
                                remaining = line[last_quote_pos + 1:].strip()
                                if not remaining.startswith(','):
                                    # Likely incomplete - close the string
                                    line = line[:last_quote_pos + 1] + '"'
                            else:
                                line = line + '"'
                    fixed_lines.append(line)
                fixed_answer = '\n'.join(fixed_lines)
                
                try:
                    parsed = json.loads(fixed_answer)
                except json.JSONDecodeError:
                    parsed = None
            
            # Strategy 3: Try to extract fields using regex if parsing still failed
            if parsed is None:
                try:
                    # Extract case
                    case_match = re.search(r'"ÿßŸÑÿ≠ÿßŸÑÿ©"\s*:\s*"([^"]+)"', answer)
                    case = case_match.group(1) if case_match else "ÿ∫Ÿäÿ± ŸÖÿ§ŸÉÿØ"
                    
                    # Extract talk - handle multi-line strings
                    # First try to find talk field with its value
                    talk_match = re.search(r'"talk"\s*:\s*"((?:[^"\\]|\\.)*)"', answer, re.DOTALL)
                    if not talk_match:
                        # Try simpler pattern
                        talk_match = re.search(r'"talk"\s*:\s*"([^"]*)"', answer)
                    talk = talk_match.group(1) if talk_match else "ŸÑÿß ÿ™Ÿàÿ¨ÿØ ŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÖÿ™ÿßÿ≠ÿ©."
                    # Clean up escape sequences
                    talk = talk.replace('\\"', '"').replace('\\n', '\n').replace('\\\\', '\\')
                    
                    # Extract sources array
                    sources_match = re.search(r'"sources"\s*:\s*\[(.*?)\]', answer, re.DOTALL)
                    sources = []
                    if sources_match:
                        sources_str = sources_match.group(1)
                        # Try to parse individual source objects
                        source_matches = re.findall(r'\{[^}]*\}', sources_str)
                        for src_match in source_matches:
                            title_match = re.search(r'"title"\s*:\s*"([^"]*)"', src_match)
                            url_match = re.search(r'"url"\s*:\s*"([^"]*)"', src_match)
                            if title_match and url_match:
                                sources.append({
                                    "title": title_match.group(1),
                                    "url": url_match.group(1)
                                })
                    
                    parsed = {
                        "ÿßŸÑÿ≠ÿßŸÑÿ©": case,
                        "talk": talk,
                        "sources": sources
                    }
                except Exception as parse_error:
                    print(f"‚ùå Failed to parse JSON with all strategies: {parse_error}")
                    # Return uncertain result as fallback
                    return {
                        "case": "ÿ∫Ÿäÿ± ŸÖÿ§ŸÉÿØ",
                        "talk": "ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ ÿ£ÿ´ŸÜÿßÿ° ŸÖÿπÿßŸÑÿ¨ÿ© ŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿ™ÿ≠ŸÇŸÇ. Ÿäÿ±ÿ¨Ÿâ ÿßŸÑŸÖÿ≠ÿßŸàŸÑÿ© ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ.",
                        "sources": [],
                        "news_article": None,
                        "x_tweet": None,
                        "source_statistics": {}
                    }

        case = parsed.get("ÿßŸÑÿ≠ÿßŸÑÿ©", "ÿ∫Ÿäÿ± ŸÖÿ§ŸÉÿØ")
        talk = parsed.get("talk", "")
        sources = parsed.get("sources", [])

        uncertain_terms = {
            "ar": {"ÿ∫Ÿäÿ± ŸÖÿ§ŸÉÿØ"},
            "en": {"uncertain"},
            "fr": {"incertain"},
            "es": {"incierto"},
            "cs": {"nejist√©", "nejiste", "nejist√°"},
            "de": {"unsicher"},
            "tr": {"belirsiz"},
            "ru": {"–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ", "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ", "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π"},
        }
        lowered = case.strip().lower()
        is_uncertain = lowered in {t for s in uncertain_terms.values() for t in s}
        
        # Prepare parallel tasks for news and tweet generation
        generation_tasks = []
        news_article = ""
        x_tweet = ""
        
        if generate_news:
            print("üì∞ Generating professional news article as requested...")
            generation_tasks.append(
                generate_professional_news_article_from_analysis_async(processed_claim, case, talk, results, lang, async_client)
            )
        
        if generate_tweet:
            print("üê¶ Generating X tweet as requested...")
            generation_tasks.append(
                generate_x_tweet_async(processed_claim, case, talk, results, lang, async_client)
            )
        
        # Execute generation tasks in parallel if any
        if generation_tasks:
            print(f"üöÄ Running {len(generation_tasks)} parallel generation tasks...")
            generation_results = await asyncio.gather(*generation_tasks)
            
            # Assign results based on what was requested
            result_idx = 0
            if generate_news:
                news_article = generation_results[result_idx]
                result_idx += 1
            if generate_tweet:
                x_tweet = generation_results[result_idx]
        
        # Clear sources for uncertain results unless explicitly requested to preserve them
        # But if preserve_sources is true, use the original search results instead of AI sources
        if is_uncertain:
            if preserve_sources:
                # Use original search results when preserving sources
                sources = [{"title": r.get("title", ""), "url": r.get("link", ""), "snippet": r.get("snippet", "")} for r in results]
            else:
                # Clear sources as per original logic
                sources = []

        # Calculate source percentages for all sources (including original search results)
        all_sources = [{"title": r.get("title", ""), "url": r.get("link", ""), "snippet": r.get("snippet", "")} for r in results]
        source_percentages = calculate_source_percentages(all_sources, processed_claim)

        return {
            "case": case, 
            "talk": talk, 
            "sources": sources,
            "news_article": news_article if generate_news else None,
            "x_tweet": x_tweet if generate_tweet else None,
            "source_statistics": source_percentages
        }

    except Exception as e:
        print("‚ùå Error:", traceback.format_exc())
        error_by_lang = {
            "ar": "‚ö†Ô∏è ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ ÿ£ÿ´ŸÜÿßÿ° ÿßŸÑÿ™ÿ≠ŸÇŸÇ.",
            "en": "‚ö†Ô∏è An error occurred during fact-checking.",
            "fr": "‚ö†Ô∏è Une erreur s'est produite lors de la v√©rification des faits.",
            "es": "‚ö†Ô∏è Se produjo un error durante la verificaci√≥n de hechos.",
            "cs": "‚ö†Ô∏è Bƒõhem ovƒõ≈ôov√°n√≠ fakt≈Ø do≈°lo k chybƒõ.",
            "de": "‚ö†Ô∏è Bei der Faktenpr√ºfung ist ein Fehler aufgetreten.",
            "tr": "‚ö†Ô∏è Doƒürulama sƒ±rasƒ±nda bir hata olu≈ütu.",
            "ru": "‚ö†Ô∏è –í–æ –≤—Ä–µ–º—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–∫—Ç–æ–≤ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞.",
        }
        try:
            lang = await _lang_hint_from_claim_async(processed_claim if 'processed_claim' in locals() else claim_text)
        except Exception:
            lang = "en"
        return {"case": "ÿ∫Ÿäÿ± ŸÖÿ§ŸÉÿØ", "talk": error_by_lang.get(lang, error_by_lang["en"]), "sources": [], "news_article": None}


# Keep synchronous version for backward compatibility - it will call async version internally
def check_fact_simple(claim_text: str, k_sources: int = 5, generate_news: bool = False, preserve_sources: bool = False, generate_tweet: bool = False) -> dict:
    """Synchronous wrapper for async fact-checking"""
    return asyncio.run(check_fact_simple_async(claim_text, k_sources, generate_news, preserve_sources, generate_tweet))

